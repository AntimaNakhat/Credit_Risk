{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwqZzXovW3rA",
        "outputId": "440073e5-5446-4320-dcce-057710e8dc22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Program is running...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy.stats import chi2_contingency\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
        "import warnings\n",
        "import os\n",
        "import time\n",
        "\n",
        "print('Program is running...')\n",
        "print()\n",
        "start_time = time.time()\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "a1 = pd.read_excel(\"/content/case_study1.xlsx\")\n",
        "a2 = pd.read_excel(\"/content/case_study2.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = a1.copy()\n",
        "df2 = a2.copy()"
      ],
      "metadata": {
        "id": "8MXrRVSmYAiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.info()"
      ],
      "metadata": {
        "id": "u8F8TaU0YBx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "840e0fa8-8c59-490a-dcb9-dc9ba1bf349e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 51336 entries, 0 to 51335\n",
            "Data columns (total 26 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   PROSPECTID            51336 non-null  int64  \n",
            " 1   Total_TL              51336 non-null  int64  \n",
            " 2   Tot_Closed_TL         51336 non-null  int64  \n",
            " 3   Tot_Active_TL         51336 non-null  int64  \n",
            " 4   Total_TL_opened_L6M   51336 non-null  int64  \n",
            " 5   Tot_TL_closed_L6M     51336 non-null  int64  \n",
            " 6   pct_tl_open_L6M       51336 non-null  float64\n",
            " 7   pct_tl_closed_L6M     51336 non-null  float64\n",
            " 8   pct_active_tl         51336 non-null  float64\n",
            " 9   pct_closed_tl         51336 non-null  float64\n",
            " 10  Total_TL_opened_L12M  51336 non-null  int64  \n",
            " 11  Tot_TL_closed_L12M    51336 non-null  int64  \n",
            " 12  pct_tl_open_L12M      51336 non-null  float64\n",
            " 13  pct_tl_closed_L12M    51336 non-null  float64\n",
            " 14  Tot_Missed_Pmnt       51336 non-null  int64  \n",
            " 15  Auto_TL               51336 non-null  int64  \n",
            " 16  CC_TL                 51336 non-null  int64  \n",
            " 17  Consumer_TL           51336 non-null  int64  \n",
            " 18  Gold_TL               51336 non-null  int64  \n",
            " 19  Home_TL               51336 non-null  int64  \n",
            " 20  PL_TL                 51336 non-null  int64  \n",
            " 21  Secured_TL            51336 non-null  int64  \n",
            " 22  Unsecured_TL          51336 non-null  int64  \n",
            " 23  Other_TL              51336 non-null  int64  \n",
            " 24  Age_Oldest_TL         51336 non-null  int64  \n",
            " 25  Age_Newest_TL         51336 non-null  int64  \n",
            "dtypes: float64(6), int64(20)\n",
            "memory usage: 10.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "ThtPHYtqYKvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcd58be-7e9e-4f8b-8365-79d68a903c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 51336 entries, 0 to 51335\n",
            "Data columns (total 62 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   PROSPECTID                    51336 non-null  int64  \n",
            " 1   time_since_recent_payment     51336 non-null  int64  \n",
            " 2   time_since_first_deliquency   51336 non-null  int64  \n",
            " 3   time_since_recent_deliquency  51336 non-null  int64  \n",
            " 4   num_times_delinquent          51336 non-null  int64  \n",
            " 5   max_delinquency_level         51336 non-null  int64  \n",
            " 6   max_recent_level_of_deliq     51336 non-null  int64  \n",
            " 7   num_deliq_6mts                51336 non-null  int64  \n",
            " 8   num_deliq_12mts               51336 non-null  int64  \n",
            " 9   num_deliq_6_12mts             51336 non-null  int64  \n",
            " 10  max_deliq_6mts                51336 non-null  int64  \n",
            " 11  max_deliq_12mts               51336 non-null  int64  \n",
            " 12  num_times_30p_dpd             51336 non-null  int64  \n",
            " 13  num_times_60p_dpd             51336 non-null  int64  \n",
            " 14  num_std                       51336 non-null  int64  \n",
            " 15  num_std_6mts                  51336 non-null  int64  \n",
            " 16  num_std_12mts                 51336 non-null  int64  \n",
            " 17  num_sub                       51336 non-null  int64  \n",
            " 18  num_sub_6mts                  51336 non-null  int64  \n",
            " 19  num_sub_12mts                 51336 non-null  int64  \n",
            " 20  num_dbt                       51336 non-null  int64  \n",
            " 21  num_dbt_6mts                  51336 non-null  int64  \n",
            " 22  num_dbt_12mts                 51336 non-null  int64  \n",
            " 23  num_lss                       51336 non-null  int64  \n",
            " 24  num_lss_6mts                  51336 non-null  int64  \n",
            " 25  num_lss_12mts                 51336 non-null  int64  \n",
            " 26  recent_level_of_deliq         51336 non-null  int64  \n",
            " 27  tot_enq                       51336 non-null  int64  \n",
            " 28  CC_enq                        51336 non-null  int64  \n",
            " 29  CC_enq_L6m                    51336 non-null  int64  \n",
            " 30  CC_enq_L12m                   51336 non-null  int64  \n",
            " 31  PL_enq                        51336 non-null  int64  \n",
            " 32  PL_enq_L6m                    51336 non-null  int64  \n",
            " 33  PL_enq_L12m                   51336 non-null  int64  \n",
            " 34  time_since_recent_enq         51336 non-null  int64  \n",
            " 35  enq_L12m                      51336 non-null  int64  \n",
            " 36  enq_L6m                       51336 non-null  int64  \n",
            " 37  enq_L3m                       51336 non-null  int64  \n",
            " 38  MARITALSTATUS                 51336 non-null  object \n",
            " 39  EDUCATION                     51336 non-null  object \n",
            " 40  AGE                           51336 non-null  int64  \n",
            " 41  GENDER                        51336 non-null  object \n",
            " 42  NETMONTHLYINCOME              51336 non-null  int64  \n",
            " 43  Time_With_Curr_Empr           51336 non-null  int64  \n",
            " 44  pct_of_active_TLs_ever        51336 non-null  float64\n",
            " 45  pct_opened_TLs_L6m_of_L12m    51336 non-null  float64\n",
            " 46  pct_currentBal_all_TL         51336 non-null  float64\n",
            " 47  CC_utilization                51336 non-null  float64\n",
            " 48  CC_Flag                       51336 non-null  int64  \n",
            " 49  PL_utilization                51336 non-null  float64\n",
            " 50  PL_Flag                       51336 non-null  int64  \n",
            " 51  pct_PL_enq_L6m_of_L12m        51336 non-null  float64\n",
            " 52  pct_CC_enq_L6m_of_L12m        51336 non-null  float64\n",
            " 53  pct_PL_enq_L6m_of_ever        51336 non-null  float64\n",
            " 54  pct_CC_enq_L6m_of_ever        51336 non-null  float64\n",
            " 55  max_unsec_exposure_inPct      51336 non-null  float64\n",
            " 56  HL_Flag                       51336 non-null  int64  \n",
            " 57  GL_Flag                       51336 non-null  int64  \n",
            " 58  last_prod_enq2                51336 non-null  object \n",
            " 59  first_prod_enq2               51336 non-null  object \n",
            " 60  Credit_Score                  51336 non-null  int64  \n",
            " 61  Approved_Flag                 51336 non-null  object \n",
            "dtypes: float64(10), int64(46), object(6)\n",
            "memory usage: 24.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Remove nulls\n",
        "df1 = df1.loc[df1['Age_Oldest_TL'] != -99999]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "columns_to_be_removed = []\n",
        "\n",
        "for i in df2.columns:\n",
        "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
        "        columns_to_be_removed .append(i)\n",
        "\n",
        "\n",
        "\n",
        "df2 = df2.drop(columns_to_be_removed, axis =1)\n",
        "\n",
        "\n",
        "\n",
        "for i in df2.columns:\n",
        "    df2 = df2.loc[ df2[i] != -99999 ]\n",
        "\n"
      ],
      "metadata": {
        "id": "kpPrHFekYRLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking common column names\n",
        "for i in list(df1.columns):\n",
        "    if i in list(df2.columns):\n",
        "        print (i)"
      ],
      "metadata": {
        "id": "W6XglRpHYaqc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80d8b93e-8bf1-4d69-92af-3e22bc069f9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROSPECTID\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge the two dataframes, inner join so that no nulls are present\n",
        "df = pd. merge ( df1, df2, how ='inner', left_on = ['PROSPECTID'], right_on = ['PROSPECTID'] )"
      ],
      "metadata": {
        "id": "_g_JG3W9YjO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check how many columns are categorical\n",
        "for i in df.columns:\n",
        "    if df[i].dtype == 'object':\n",
        "        print(i)"
      ],
      "metadata": {
        "id": "9FAv7RB6Ylul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e512348-3851-4f9c-b9f3-732266ff3bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MARITALSTATUS\n",
            "EDUCATION\n",
            "GENDER\n",
            "last_prod_enq2\n",
            "first_prod_enq2\n",
            "Approved_Flag\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chi-square test\n",
        "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
        "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
        "    print(i, '---', pval)"
      ],
      "metadata": {
        "id": "rdSzLIS3Yofw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1f9b22-2297-45cd-e79d-28158f8b3fa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MARITALSTATUS --- 3.578180861038862e-233\n",
            "EDUCATION --- 2.6942265249737532e-30\n",
            "GENDER --- 1.907936100186563e-05\n",
            "last_prod_enq2 --- 0.0\n",
            "first_prod_enq2 --- 7.84997610555419e-287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VIF for numerical columns\n",
        "numeric_columns = []\n",
        "for i in df.columns:\n",
        "    if df[i].dtype != 'object' and i not in ['PROSPECTID','Approved_Flag']:\n",
        "        numeric_columns.append(i)"
      ],
      "metadata": {
        "id": "wM6inGFtYq8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VIF sequentially check\n",
        "\n",
        "vif_data = df[numeric_columns]\n",
        "total_columns = vif_data.shape[1]\n",
        "columns_to_be_kept = []\n",
        "column_index = 0\n"
      ],
      "metadata": {
        "id": "8A-aLcl_Ys_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,total_columns):\n",
        "\n",
        "    vif_value = variance_inflation_factor(vif_data, column_index)\n",
        "    print (column_index,'---',vif_value)\n",
        "\n",
        "\n",
        "    if vif_value <= 6:\n",
        "        columns_to_be_kept.append( numeric_columns[i] )\n",
        "        column_index = column_index+1\n",
        "\n",
        "    else:\n",
        "        vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)"
      ],
      "metadata": {
        "id": "cPq2oYr6YvO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de61033-2f88-4d00-801a-e9abc0d8978d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 --- inf\n",
            "0 --- inf\n",
            "0 --- 11.320180023967996\n",
            "0 --- 8.363698035000327\n",
            "0 --- 6.520647877790928\n",
            "0 --- 5.149501618212625\n",
            "1 --- 2.611111040579735\n",
            "2 --- inf\n",
            "2 --- 1788.7926256209232\n",
            "2 --- 8.601028256477228\n",
            "2 --- 3.8328007921530785\n",
            "3 --- 6.099653381646723\n",
            "3 --- 5.581352009642766\n",
            "4 --- 1.9855843530987776\n",
            "5 --- inf\n",
            "5 --- 4.809538302819343\n",
            "6 --- 23.270628983464636\n",
            "6 --- 30.595522588100053\n",
            "6 --- 4.3843464059655854\n",
            "7 --- 3.064658415523423\n",
            "8 --- 2.898639771299253\n",
            "9 --- 4.377876915347322\n",
            "10 --- 2.207853583695844\n",
            "11 --- 4.916914200506861\n",
            "12 --- 5.214702030064725\n",
            "13 --- 3.3861625024231476\n",
            "14 --- 7.840583309478997\n",
            "14 --- 5.255034641721438\n",
            "15 --- inf\n",
            "15 --- 7.380634506427238\n",
            "15 --- 1.4210050015175735\n",
            "16 --- 8.083255010190316\n",
            "16 --- 1.624122752404011\n",
            "17 --- 7.257811920140003\n",
            "17 --- 15.59624383268298\n",
            "17 --- 1.8258570471324318\n",
            "18 --- 1.5080839450032664\n",
            "19 --- 2.1720888348245753\n",
            "20 --- 2.623397553527229\n",
            "21 --- 2.2959970812106167\n",
            "22 --- 7.360578319196439\n",
            "22 --- 2.1602387773102554\n",
            "23 --- 2.8686288267891444\n",
            "24 --- 6.458218003637272\n",
            "24 --- 2.847411886563824\n",
            "25 --- 4.75319815628408\n",
            "26 --- 16.22735475594825\n",
            "26 --- 6.424377256363877\n",
            "26 --- 8.887080381808678\n",
            "26 --- 2.3804746142952666\n",
            "27 --- 8.609513476514548\n",
            "27 --- 13.06755093547673\n",
            "27 --- 3.500040056654653\n",
            "28 --- 1.9087955874813773\n",
            "29 --- 17.006562234161628\n",
            "29 --- 10.730485153719197\n",
            "29 --- 2.3538497522950275\n",
            "30 --- 22.104855915136433\n",
            "30 --- 2.7971639638512915\n",
            "31 --- 3.424171203217697\n",
            "32 --- 10.175021454450922\n",
            "32 --- 6.408710354561292\n",
            "32 --- 1.001151196262563\n",
            "33 --- 3.069197305397274\n",
            "34 --- 2.8091261600643707\n",
            "35 --- 20.249538381980678\n",
            "35 --- 15.864576541593745\n",
            "35 --- 1.8331649740532152\n",
            "36 --- 1.5680839909542044\n",
            "37 --- 1.9307572353811688\n",
            "38 --- 4.331265056645249\n",
            "39 --- 9.390334396150173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check Anova for columns_to_be_kept\n",
        "\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "columns_to_be_kept_numerical = []\n",
        "\n",
        "for i in columns_to_be_kept:\n",
        "    a = list(df[i])\n",
        "    b = list(df['Approved_Flag'])\n",
        "\n",
        "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
        "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
        "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
        "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
        "\n",
        "\n",
        "    f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
        "\n",
        "    if p_value <= 0.05:\n",
        "        columns_to_be_kept_numerical.append(i)\n"
      ],
      "metadata": {
        "id": "JsjYBd3jYx1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature selection is done for cat and num features\n"
      ],
      "metadata": {
        "id": "KqjZ_JO0Y8Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# listing all the final features\n",
        "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']\n",
        "df = df[features + ['Approved_Flag']]"
      ],
      "metadata": {
        "id": "vWHz085pZjOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Label encoding for the categorical features\n",
        "['MARITALSTATUS', 'EDUCATION', 'GENDER' , 'last_prod_enq2' ,'first_prod_enq2']"
      ],
      "metadata": {
        "id": "vX9DDdjLZjqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44561ca-6950-4d5a-9725-29fb9719751d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinal feature -- EDUCATION\n",
        "df.loc[df['EDUCATION'] == 'SSC',['EDUCATION']]              = 1\n",
        "df.loc[df['EDUCATION'] == '12TH',['EDUCATION']]             = 2\n",
        "df.loc[df['EDUCATION'] == 'GRADUATE',['EDUCATION']]         = 3\n",
        "df.loc[df['EDUCATION'] == 'UNDER GRADUATE',['EDUCATION']]   = 3\n",
        "df.loc[df['EDUCATION'] == 'POST-GRADUATE',['EDUCATION']]    = 4\n",
        "df.loc[df['EDUCATION'] == 'OTHERS',['EDUCATION']]           = 1\n",
        "df.loc[df['EDUCATION'] == 'PROFESSIONAL',['EDUCATION']]     = 3\n"
      ],
      "metadata": {
        "id": "kDk3uubJZsH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])\n"
      ],
      "metadata": {
        "id": "iY8ItY0NjW9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Machine Learing model fitting\n"
      ],
      "metadata": {
        "id": "GRJ46jzmkaxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "AOfJcjdNkaz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Random Forest\n",
        "\n",
        "y = df_encoded['Approved_Flag']\n",
        "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
        "rf_classifier.fit(x_train, y_train)\n",
        "y_pred = rf_classifier.predict(x_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print ()\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print ()\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "\n",
        "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
        "    print(f\"Class {v}:\")\n",
        "    print(f\"Precision: {precision[i]}\")\n",
        "    print(f\"Recall: {recall[i]}\")\n",
        "    print(f\"F1 Score: {f1_score[i]}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "VaTjzTD9ka3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03a279c-cb0e-475f-a9c6-8b27b1a770a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.7636990372043266\n",
            "\n",
            "Class p1:\n",
            "Precision: 0.8370457209847597\n",
            "Recall: 0.7041420118343196\n",
            "F1 Score: 0.7648634172469202\n",
            "\n",
            "Class p2:\n",
            "Precision: 0.7957519116397621\n",
            "Recall: 0.9282457879088206\n",
            "F1 Score: 0.856907593778591\n",
            "\n",
            "Class p3:\n",
            "Precision: 0.4423380726698262\n",
            "Recall: 0.21132075471698114\n",
            "F1 Score: 0.28600612870275793\n",
            "\n",
            "Class p4:\n",
            "Precision: 0.7178502879078695\n",
            "Recall: 0.7269193391642371\n",
            "F1 Score: 0.7223563495895703\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# 2. xgboost\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4, enable_categorical=True) # Added enable_categorical=True\n",
        "\n",
        "y = df_encoded['Approved_Flag']\n",
        "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
        "\n",
        "# Convert 'EDUCATION' column to numeric type\n",
        "x['EDUCATION'] = pd.to_numeric(x['EDUCATION']) # convert to numeric\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "xgb_classifier.fit(x_train, y_train)\n",
        "y_pred = xgb_classifier.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print ()\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print ()\n",
        "\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
        "    print(f\"Class {v}:\")\n",
        "    print(f\"Precision: {precision[i]}\")\n",
        "    print(f\"Recall: {recall[i]}\")\n",
        "    print(f\"F1 Score: {f1_score[i]}\")\n",
        "    print()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ZEZyNE03lI0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78760da5-b0dd-47ed-e755-15899d817126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.78\n",
            "\n",
            "Class p1:\n",
            "Precision: 0.823906083244397\n",
            "Recall: 0.7613412228796844\n",
            "F1 Score: 0.7913890312660175\n",
            "\n",
            "Class p2:\n",
            "Precision: 0.8255418233924413\n",
            "Recall: 0.913577799801784\n",
            "F1 Score: 0.8673315769665035\n",
            "\n",
            "Class p3:\n",
            "Precision: 0.4756380510440835\n",
            "Recall: 0.30943396226415093\n",
            "F1 Score: 0.37494284407864653\n",
            "\n",
            "Class p4:\n",
            "Precision: 0.7342386032977691\n",
            "Recall: 0.7356656948493683\n",
            "F1 Score: 0.7349514563106796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 3. Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "y = df_encoded['Approved_Flag']\n",
        "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
        "dt_model.fit(x_train, y_train)\n",
        "y_pred = dt_model.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print ()\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print ()\n",
        "\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
        "\n",
        "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
        "    print(f\"Class {v}:\")\n",
        "    print(f\"Precision: {precision[i]}\")\n",
        "    print(f\"Recall: {recall[i]}\")\n",
        "    print(f\"F1 Score: {f1_score[i]}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "pSNTtoVpka95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d32f446-b87b-40b2-a114-a2137df3b4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy: 0.71\n",
            "\n",
            "Class p1:\n",
            "Precision: 0.7203140333660452\n",
            "Recall: 0.7238658777120316\n",
            "F1 Score: 0.7220855878012788\n",
            "\n",
            "Class p2:\n",
            "Precision: 0.810468962833236\n",
            "Recall: 0.8255698711595639\n",
            "F1 Score: 0.8179497250589159\n",
            "\n",
            "Class p3:\n",
            "Precision: 0.3457573354480571\n",
            "Recall: 0.3290566037735849\n",
            "F1 Score: 0.337200309358082\n",
            "\n",
            "Class p4:\n",
            "Precision: 0.6519114688128773\n",
            "Recall: 0.6297376093294461\n",
            "F1 Score: 0.6406327236777064\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost is giving me best results so we will further finetune it\n"
      ],
      "metadata": {
        "id": "MPmuB_uZkbA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply standard scaler\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "columns_to_be_scaled = ['Age_Oldest_TL','Age_Newest_TL','time_since_recent_payment',\n",
        "'max_recent_level_of_deliq','recent_level_of_deliq',\n",
        "'time_since_recent_enq','NETMONTHLYINCOME','Time_With_Curr_Empr']\n",
        "\n",
        "for i in columns_to_be_scaled:\n",
        "    column_data = df_encoded[i].values.reshape(-1, 1)\n",
        "    scaler = StandardScaler()\n",
        "    scaled_column = scaler.fit_transform(column_data)\n",
        "    df_encoded[i] = scaled_column"
      ],
      "metadata": {
        "id": "gcXHraToPrXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Hyperparameter tuning in xgboost\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure 'EDUCATION' is numeric in both training and testing sets\n",
        "x_train['EDUCATION'] = pd.to_numeric(x_train['EDUCATION'])\n",
        "x_test['EDUCATION'] = pd.to_numeric(x_test['EDUCATION'])\n",
        "\n",
        "# Define the XGBClassifier with the initial set of hyperparameters\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the model with the best hyperparameters on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "accuracy = best_model.score(x_test, y_test)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "DW4fmfA3PrjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50698741-c29f-4b92-9622-70826550cb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
            "Test Accuracy: 0.7811719957209081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n"
      ],
      "metadata": {
        "id": "LC4w6DsoPrlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on risk appetite of the bank, you will suggest P1,P2,P3,P4 to the business end user\n"
      ],
      "metadata": {
        "id": "iMMzGMZVProM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the model\n",
        "with open('model.pkl', 'wb') as file:\n",
        "    pickle.dump(xgb_model, file)\n",
        "\n",
        "print(\"Pickle file saved successfully!\")"
      ],
      "metadata": {
        "id": "iPieoLCjkbJ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177b2abd-4efc-4d77-cc13-f3aee9f1d93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pickle file saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "with open('model.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)\n",
        "\n",
        "print(\"Pickle file loaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bY35HNjWMOi",
        "outputId": "e2038de1-9e53-44bc-f265-9423e3262f8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pickle file loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oiMe3RysW7iU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}